{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f1b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a249b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock_ta = pd.read_csv('temp/stock_ta.csv')\n",
    "df_stock_cdl = pd.read_csv('temp/stock_cdl.csv')\n",
    "df_ind_ta = pd.read_csv('temp/ind_ta.csv')\n",
    "df_ind_cdl = pd.read_csv('temp/ind_cdl.csv')\n",
    "df_stock_news = pd.read_csv('temp/stock_news.csv')\n",
    "df_ind_news = pd.read_csv('temp/ind_news.csv')\n",
    "\n",
    "df_tar = pd.read_csv('temp/target.csv')\n",
    "df_tar = df_tar[['report_date', 'ticker', 'label']]\n",
    "# df_stock_ta = df_stock_ta.drop(['open', 'high', 'low', 'close', 'volume', 'adjusted_close'], axis = 1)\n",
    "# df_ind_ta = df_ind_ta.drop(['open', 'high', 'low', 'close', 'volume', 'adjusted_close'], axis = 1)\n",
    "\n",
    "# Prepare Cross Industrial Feature\n",
    "df_inds = df_ind_cdl.merge(df_ind_news, on = ['inds', 'report_date'], how = 'left')\n",
    "df_inds = df_inds.merge(df_ind_ta, on = ['report_date', 'inds'])\n",
    "df_inds = df_inds.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6887f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 7; train_size = 0.8; prepare_3d = False\n",
    "require_features = ['cdl', 'ta', 'news']\n",
    "inds_num = len(df_inds['inds'].unique())\n",
    "\n",
    "price_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "cdl_cols = ['morning_star', 'evening_star', 'hammer',\n",
    "       'inverted_hammer', 'bullish_engulfing', 'bearish_engulfing',\n",
    "       'shooting_star', 'hanging_man']\n",
    "news_cols = ['compound', 'neg', 'neu', 'pos', 'new_cases',\n",
    "       'total_cases', 'total_deaths', 'new_deaths', 'total_deaths_nd']\n",
    "ta_cols = df_stock_ta.drop(['report_date', 'ticker'], axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8527c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Stock:  MMM\n",
      "Current Stock:  AOS\n",
      "Current Stock:  ABT\n",
      "Current Stock:  ABBV\n",
      "Current Stock:  ABMD\n",
      "Current Stock:  ACN\n",
      "Current Stock:  ATVI\n",
      "Current Stock:  ADM\n",
      "Current Stock:  ADBE\n",
      "Current Stock:  ADP\n",
      "Current Stock:  AAP\n",
      "Current Stock:  AES\n",
      "Current Stock:  AFL\n",
      "Current Stock:  A\n",
      "Current Stock:  APD\n",
      "Current Stock:  AKAM\n",
      "Current Stock:  ALK\n",
      "Current Stock:  ALB\n",
      "Current Stock:  ARE\n",
      "Current Stock:  ALGN\n",
      "Current Stock:  ALLE\n",
      "Current Stock:  LNT\n",
      "Current Stock:  ALL\n",
      "Current Stock:  GOOGL\n",
      "Current Stock:  GOOG\n",
      "Current Stock:  MO\n"
     ]
    }
   ],
   "source": [
    "# Prepare Train test dataset preparation\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "stocks = df_tar['ticker'].unique()\n",
    "for stock in stocks:\n",
    "    \n",
    "    print('Current Stock: ', stock)\n",
    "    temp_stock_cdl = df_stock_cdl[df_stock_cdl['ticker'] == stock]\n",
    "    temp_stock_ta = df_stock_ta[df_stock_ta['ticker'] == stock]\n",
    "    temp_stock_news = df_stock_news[df_stock_news['ticker'] == stock]\n",
    "    temp_stock_tar = df_tar[df_tar['ticker'] == stock]\n",
    "    \n",
    "    # Merge results\n",
    "    data = temp_stock_tar.merge(temp_stock_cdl, on = ['report_date', 'ticker'])\n",
    "    data = data.merge(temp_stock_ta, on = ['report_date', 'ticker'])\n",
    "    data = data.merge(temp_stock_news, on = ['report_date', 'ticker'], how = 'left')\n",
    "    data = data.fillna(method = 'ffill')\n",
    "    \n",
    "    check = True\n",
    "    for i in range(period, len(data)):\n",
    "        \n",
    "        temp = []\n",
    "        # Create historical data (within period)\n",
    "        temp_period = data.iloc[i - period:i,]\n",
    "        if temp_period.isnull().sum().sum() > 0:\n",
    "            continue\n",
    "\n",
    "        # Create stock feature space\n",
    "        feature_dfs = []\n",
    "        feature_dfs.append(temp_period[price_cols])\n",
    "        \n",
    "        if 'cdl' in require_features:\n",
    "            feature_dfs.append(temp_period[cdl_cols])\n",
    "            \n",
    "        if 'news' in require_features:\n",
    "            feature_dfs.append(temp_period[news_cols])\n",
    "            \n",
    "        if 'ta' in require_features:\n",
    "            feature_dfs.append(temp_period[ta_cols])\n",
    "            \n",
    "        temp_stock_feature = pd.concat(feature_dfs, axis = 1).to_numpy()\n",
    "        temp.append(temp_stock_feature)\n",
    "        \n",
    "        # Get industrial feature space\n",
    "        for ind in sorted(list(df_inds['inds'].unique())):\n",
    "            temp_period_inds = df_inds[df_inds['inds'] == ind].reset_index(drop = True).iloc[i - period:i,]\n",
    "            \n",
    "            feature_ind_dfs = []\n",
    "            feature_ind_dfs.append(temp_period_inds[price_cols])\n",
    "            if 'cdl' in require_features:\n",
    "                feature_ind_dfs.append(temp_period_inds[cdl_cols])\n",
    "\n",
    "            if 'news' in require_features:\n",
    "                feature_ind_dfs.append(temp_period_inds[news_cols])\n",
    "\n",
    "            if 'ta' in require_features:\n",
    "                feature_ind_dfs.append(temp_period_inds[ta_cols])\n",
    "                \n",
    "            temp_ind_feature = pd.concat(feature_ind_dfs, axis = 1).to_numpy()\n",
    "            temp.append(temp_ind_feature)\n",
    "        \n",
    "        # Create label \n",
    "        y_label = temp_period.iloc[-1]['label']\n",
    "        \n",
    "        if i <= int((len(data) - period) * train_size):\n",
    "            \n",
    "#             if check:\n",
    "#                 print('train', i)\n",
    "#                 print('max report_date: ', max(temp_period['report_date']), 'min report_date: ', min(temp_period['report_date']))\n",
    "#                 print('Whole feature shape: ', np.array(temp).shape)\n",
    "#                 print('label: ', y_label)\n",
    "#                 check = False\n",
    "\n",
    "            X_train.append(temp)\n",
    "            y_train.append(y_label)\n",
    "        else: \n",
    "            X_test.append(temp)\n",
    "            y_test.append(y_label)\n",
    "        \n",
    "X_train, y_train = np.array(X_train).astype('float32'), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test).astype('float32'), np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c3cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide to multiple combinations\n",
    "cond_dict = {}\n",
    "feature_idx_dict = {name: ind for ind, name in enumerate(pd.concat(feature_dfs, axis = 1).columns)}\n",
    "adj_news_cols = ['compound', 'pos', 'new_deaths', 'new_deaths_nd']\n",
    "\n",
    "# Candlestick + TA + News\n",
    "feature_idx = [idx for name, idx in feature_idx_dict.items() \\\n",
    "                   if name in price_cols + cdl_cols + adj_news_cols + list(ta_cols)]\n",
    "cond_dict['All'] = {'train': X_train[:, :, :, feature_idx], 'test': X_test[:, :, :, feature_idx]}\n",
    "\n",
    "# Candlestick + News\n",
    "feature_idx = [idx for name, idx in feature_idx_dict.items() if name in price_cols + cdl_cols + adj_news_cols]\n",
    "cond_dict['Candlestick+News'] = {'train': X_train[:, :, :, feature_idx], 'test': X_test[:, :, :, feature_idx]}\n",
    "\n",
    "# Candlestick + TA\n",
    "feature_idx = [idx for name, idx in feature_idx_dict.items() if name in price_cols + cdl_cols + list(ta_cols)]\n",
    "cond_dict['Candlestick+TA'] = {'train': X_train[:, :, :, feature_idx], 'test': X_test[:, :, :, feature_idx]}\n",
    "\n",
    "# Candlestick Only\n",
    "feature_idx = [idx for name, idx in feature_idx_dict.items() if name in price_cols + cdl_cols]\n",
    "cond_dict['CandlestickOnly'] = {'train': X_train[:, :, :, feature_idx], 'test': X_test[:, :, :, feature_idx]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da32582",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59feae97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TimothyLo_1/miniforge3/envs/env_tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for All:  64.47 %\n",
      "Testing Accuracy for All:  65.94 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TimothyLo_1/miniforge3/envs/env_tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Candlestick+News:  66.18 %\n",
      "Testing Accuracy for Candlestick+News:  41.78 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TimothyLo_1/miniforge3/envs/env_tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Candlestick+TA:  64.01 %\n",
      "Testing Accuracy for Candlestick+TA:  61.04 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TimothyLo_1/miniforge3/envs/env_tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for CandlestickOnly:  74.0 %\n",
      "Testing Accuracy for CandlestickOnly:  62.08 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Loop over each feature type and fit the model\n",
    "for feature_type, data in cond_dict.items():\n",
    "    \n",
    "    temp_train = data['train']\n",
    "    temp_test = data['test']\n",
    "\n",
    "    if not prepare_3d:\n",
    "        temp_train = temp_train.reshape(temp_train.shape[0], -1)\n",
    "        temp_test = temp_test.reshape(temp_test.shape[0], -1)\n",
    "\n",
    "    clf = LogisticRegression(random_state = 7600)\n",
    "    clf.fit(temp_train, y_train)\n",
    "\n",
    "    print(f'Training Accuracy for {feature_type}: ', round(clf.score(temp_train, y_train) * 100, 2), '%')\n",
    "    print(f'Testing Accuracy for {feature_type}: ', round(clf.score(temp_test, y_test) * 100, 2), '%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bced0",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6df243b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for All:  78.37 %\n",
      "Testing Accuracy for All:  49.05 %\n",
      "\n",
      "Training Accuracy for Candlestick+News:  75.89 %\n",
      "Testing Accuracy for Candlestick+News:  57.27 %\n",
      "\n",
      "Training Accuracy for Candlestick+TA:  78.54 %\n",
      "Testing Accuracy for Candlestick+TA:  51.52 %\n",
      "\n",
      "Training Accuracy for CandlestickOnly:  76.84 %\n",
      "Testing Accuracy for CandlestickOnly:  55.51 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Loop over each feature type and fit the model\n",
    "for feature_type, data in cond_dict.items():\n",
    "    \n",
    "    temp_train = data['train']\n",
    "    temp_test = data['test']\n",
    "\n",
    "    if not prepare_3d:\n",
    "        temp_train = temp_train.reshape(temp_train.shape[0], -1)\n",
    "        temp_test = temp_test.reshape(temp_test.shape[0], -1)\n",
    "\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(temp_train, y_train)\n",
    "\n",
    "    print(f'Training Accuracy for {feature_type}: ', round(clf.score(temp_train, y_train) * 100, 2), '%')\n",
    "    print(f'Testing Accuracy for {feature_type}: ', round(clf.score(temp_test, y_test) * 100, 2), '%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a453d",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decission Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "prepare_3d = False\n",
    "# Loop over each feature type and fit the model\n",
    "for feature_type, data in cond_dict.items():\n",
    "    \n",
    "    temp_train = data['train']\n",
    "    temp_test = data['test']\n",
    "\n",
    "    if not prepare_3d:\n",
    "        temp_train = temp_train.reshape(temp_train.shape[0], -1)\n",
    "        temp_test = temp_test.reshape(temp_test.shape[0], -1)\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state = 7600)\n",
    "    clf.fit(temp_train, y_train)\n",
    "\n",
    "    print(f'Training Accuracy for {feature_type}: ', round(clf.score(temp_train, y_train) * 100, 2), '%')\n",
    "    print(f'Testing Accuracy for {feature_type}: ', round(clf.score(temp_test, y_test) * 100, 2), '%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd3636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e24093",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afb5c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for All:  100.0 %\n",
      "Testing Accuracy for All:  61.82 %\n",
      "\n",
      "Training Accuracy for Candlestick+News:  100.0 %\n",
      "Testing Accuracy for Candlestick+News:  49.68 %\n",
      "\n",
      "Training Accuracy for Candlestick+TA:  100.0 %\n",
      "Testing Accuracy for Candlestick+TA:  62.57 %\n",
      "\n",
      "Training Accuracy for CandlestickOnly:  100.0 %\n",
      "Testing Accuracy for CandlestickOnly:  62.01 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Loop over each feature type and fit the model\n",
    "for feature_type, data in cond_dict.items():\n",
    "    \n",
    "    temp_train = data['train']\n",
    "    temp_test = data['test']\n",
    "\n",
    "    if not prepare_3d:\n",
    "        temp_train = temp_train.reshape(temp_train.shape[0], -1)\n",
    "        temp_test = temp_test.reshape(temp_test.shape[0], -1)\n",
    "\n",
    "    clf = RandomForestClassifier(random_state = 7600)\n",
    "    clf.fit(temp_train, y_train)\n",
    "\n",
    "    print(f'Training Accuracy for {feature_type}: ', round(clf.score(temp_train, y_train) * 100, 2), '%')\n",
    "    print(f'Testing Accuracy for {feature_type}: ', round(clf.score(temp_test, y_test) * 100, 2), '%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355257a",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51b042f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for All:  77.85 %\n",
      "Testing Accuracy for All:  62.6 %\n",
      "Training Accuracy for Candlestick+News:  75.44 %\n",
      "Testing Accuracy for Candlestick+News:  62.44 %\n",
      "Training Accuracy for Candlestick+TA:  77.9 %\n",
      "Testing Accuracy for Candlestick+TA:  64.86 %\n",
      "Training Accuracy for CandlestickOnly:  75.15 %\n",
      "Testing Accuracy for CandlestickOnly:  64.27 %\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param = {'max_depth':2, 'eta':1, 'objective':'binary:logistic' }\n",
    "param['eval_metric'] = 'auc'\n",
    "num_round = 100\n",
    "\n",
    "# Loop over each feature type and fit the model\n",
    "for feature_type, data in cond_dict.items():\n",
    "    \n",
    "    temp_train = data['train']\n",
    "    temp_test = data['test']\n",
    "\n",
    "    if not prepare_3d:\n",
    "        temp_train = temp_train.reshape(temp_train.shape[0], -1)\n",
    "        temp_test = temp_test.reshape(temp_test.shape[0], -1)\n",
    "\n",
    "    dtrain = xgb.DMatrix(temp_train, label = y_train)\n",
    "    dtest = xgb.DMatrix(temp_test, label = y_test)\n",
    "        \n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict(dtest)\n",
    "\n",
    "    print(f'Training Accuracy for {feature_type}: ', round(np.mean((bst.predict(dtrain) > 0.5) == y_train) * 100, 2), '%')\n",
    "    print(f'Testing Accuracy for {feature_type}: ', round(np.mean((preds > 0.5) == y_test) * 100, 2), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b245e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca923c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
